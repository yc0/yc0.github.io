[{"content":"System Activity Reporter Tool Summary sar is an abbreviation for System Activity Reporter and is described as a powerful tool for diagnosing system bottlenecks. It works by continuously sampling the current system state and calculating data and ratios to provide a comprehensive report on the system\u0026rsquo;s operational status.\nKey Characteristics Comprehensive: Considered one of the most comprehensive performance analysis tools on Linux, reporting on up to 14 major aspects of system activity. Low Overhead: The process of collecting data and storing results in a file requires very little system load. Wide Scope: Can report on file I/O, system calls, CPU efficiency, memory usage, process activity, inter-process communication (IPC), and more. Usage Modes sar primarily supports two ways of viewing system data:\nTracing Past Data (Default): It can retrieve historical data, typically starting from the beginning of the current day. Older reports are stored in log files under /var/log/sysstat/ (e.g., sa28), which can be viewed using the -f option (e.g., sar -f /var/log/sysstat/sa28). Periodically Viewing Current Data: It can be used to monitor real-time system activity over a specified interval and count. Core Monitoring Metrics (Examples) The tool uses specific options to display different categories of system statistics:\nCommand Metric Description of Key Fields sar -u CPU Utilization Shows %user, %system, %iowait (CPU idle waiting for I/O), and %idle. sar -q Average Load Reports runq-sz (run queue length/waiting processes) and average loads (ldavg-1, ldavg-5, ldavg-15). sar -r Memory Usage Displays kbmemfree, kbmemused, %memused, kbbuffers, and kbcached. sar -W Paging/Swap Activity Monitors page-in (pswpin/s) and page-out (pswpout/s) rates, which are key indicators of memory shortages. Diagnosing System Bottlenecks sar reports are often combined to effectively pinpoint the cause of poor performance:\nCPU Bottleneck: Use sar -u and sar -q. Memory Bottleneck: Use sar -B, sar -r, and sar -W. I/O Bottleneck: Use sar -b, sar -u, and sar -d. Installation and Setup The sar tool is part of the sysstat package.\nInstallation: Install the package using a system package manager (e.g., apt-get install sysstat on Debian/Ubuntu systems). Enabling Data Collection: Edit the configuration file, typically located at /etc/default/sysstat, and set ENABLED=\u0026quot;true\u0026quot;. Starting the Service: Start the performance data collection service (e.g., /etc/init.d/sysstat start). General Parameters The tool offers many parameters to customize the report output, including:\n-A: Summarizes all available reports. -b: Reports I/O and buffer usage. -d: Reports disk usage. -r: Reports memory usage. -u: Reports CPU utilization. -q: Reports run queue and load average. -W: Reports system swap activity. Reference https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/sar.html\n","permalink":"https://yc0.github.io/posts/sar-linux-tools/","summary":"\u003ch1 id=\"system-activity-reporter-tool-summary\"\u003eSystem Activity Reporter Tool Summary\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003esar\u003c/code\u003e is an abbreviation for \u003cstrong\u003eSystem Activity Reporter\u003c/strong\u003e and is described as a powerful tool for diagnosing system bottlenecks. It works by continuously sampling the current system state and calculating data and ratios to provide a comprehensive report on the system\u0026rsquo;s operational status.\u003c/p\u003e\n\u003ch2 id=\"key-characteristics\"\u003eKey Characteristics\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eComprehensive:\u003c/strong\u003e Considered one of the most comprehensive performance analysis tools on Linux, reporting on up to 14 major aspects of system activity.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLow Overhead:\u003c/strong\u003e The process of collecting data and storing results in a file requires very little system load.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWide Scope:\u003c/strong\u003e Can report on file I/O, system calls, CPU efficiency, memory usage, process activity, inter-process communication (IPC), and more.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"usage-modes\"\u003eUsage Modes\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003esar\u003c/code\u003e primarily supports two ways of viewing system data:\u003c/p\u003e","title":"SAR Linux Tools"},{"content":"Describe OpenShift Container Platform Overview An application manages Kubernetes resources: Operator An application manages Kubernetes operators : Operator Lifecycle Manager(OLM) A repo. for discovering and installing operators : Operator Catelog Regular operators that are not managed by the OLM. They are managed by OpenShift Cluster Version Operator : Cluster Operators OpenShift Cluster Version Operator : First-level operator Cluster Operators are called second-level operators Summary Red Hat OpenShift Platform is based on Red Hat CoreOS, CRI-O and Kubernetes RHOCP 4 provides a number of services on top of Kubernetes, such as an internal container image registry, storage, networking providers, and centralized logging and monitoring. Operators package applications that manage Kubernetes resources, and the Operator Lifecycle Manager (OLM) handles installation and management of operators. OperatorHub.io is an online catalog for discovering operators. Installation IPI Full-Stack Installation Only this way can fulfil cluster scaling http://try.openshift.org It does\u0026rsquo;t have to be part of cluster UPI User provisioned Infrastructure for pre-existing environment CoreOS and RHEL Control Panel must run on CoreOS Workers can run either CoreOS or RHEL Installation-config.yaml the rest of resource domain name following {metadata.name} + {baseDomain} network configuration cannot reconfigure easily after cluster is up and running. Initial deployment process there\u0026rsquo;s no much customization UPI mode has to do node certficate when dial to master node (control plane) by manual whereas IPI has no requirment. Summary two main installation methods full-stack automation pre-existing infrastructures. OpenShift node based on Red Hat Enterprise Linux CoreOS runs very few local services Most of the system run as containers CRI-O and kubelet Troubleshooting oc get node oc adm top oc adm node-logs oc adm debug Trouble Shooting oc adm node-log oc log oc logs {podname} --all-containers oc logs {podname} -c {} oc debug what went wrong during POD startup oc debug {pod|deployment} --as-root oc rsh $ oc exec -it {podname} -- {command} {--options} $ oc exec -it {podname} -c {container} -- {command} {--options} shorter equivalent\n$ oc rsh {podname} Note why we need \u0026ndash; ?\nYou must use two dashes (\u0026ndash;) to separate your command\u0026rsquo;s flags/arguments Identity Providers Concept Describe User Users are entities An actor within the system Interact with the API server Assign permissions by adding roles The user is a member of the group Identity A resource that keeps a record of successful authentication attempts from a specific user and identity provider A single user resource is associated with an identity resource. Service Account Applications can communicate with the API independently Service accounts enable you to control API access with Service Account credentials. Group Groups represent a specific set of users Users are assigned to one or to multiple groups. implementing authorization policies to assign permissions to multiple users at the same time. Role A set of permissions that enables a user to perform API operations over one or more resource types. (Verb + Resources) Summary Creating Users Requires valid credentials managed by an identity provider, user and identity resources\nDeleting Users Deleting their credentials from the identity provider, and also deleting their user and identity resources.\nTwo authentication methods kubeconfig : not recommand, super priviledge. kubeadmin virtual user OAuth Custom Resource HTPasswd Identity Provider htpasswd extract data from secret/store in a secret Assign cluster-admin role to the user to grant a user cluser admin priviledge. Role-based Access Control, RBAC In OpenShift, RBAC determines if a user can perform certain actions within the cluster or project. There\u0026rsquo;re two types of roles:\nCluster Local. Concept Project V.S. Cluster Actually for rolebinding resource creation\nProject Scope add-role-to-user oc policy add-role-to-user {role} {user} {-n option} it\u0026rsquo;s better to assign specific namespace to make sure we delegate the designate namespace toward user\nfor example\n$ oc policy add-role-to-user view developer -n test-namespace add-role-to-group remove-role-from-user remove-role-from-group Cluster Scope add-cluster-role-to-user add-cluster-role-to-group remove-cluster-role-from-user remove-cluster-role-from-group Who can oc adm policy who-can {verb} {resource}\nfor example\n$ oc adm policy who-can create projects However, in OpenShift, you cannot directly create project as prioi to mention.\nOpenShift adopts a mechanism projectrequest resource to automatically on the background for making sure the project is created according to certain of settings and\nAdmin Role V.S. Edit Role no role related resources on Edit Role no delete/patch/update permission for projects and namespaces on Edit Role Service Account, SA When a person uses the command line or web console, their API token authenticates them to the OpenShift API. However, when a regular user’s credentials are not available, it is common for components to make API calls independently. For example:\nReplication controllers make API calls to create or delete pods Applications inside containers could make API calls for discovery purposes External applications could make API calls for monitoring or integration purposes Service accounts provide a flexible way to control API access without sharing a regular user’s credentials.\nexist within the scope of a project that is to say, if there\u0026rsquo;re the SAs with the same name, they are totally different objects though. Security Context Constraints, SCC security context constraints, SCC, that control the actions that a pod can perform and what it has the ability to access.\nConcept it evaluates at pod creation time Pod is with the correct SCC, it has to be deleted and be recreated it controls Running privileged containers Requesting extra capabilities to a container Using host directories as volumes Changing the SELinux context of a container Changing the user ID Capabilities Also refer to POSIX capabilities, you can look up piece of information in Linux. The capabilities would be add or remove from the processes running inside the containers\n$ man 7 capabilities Prioitization highest priority first, nil is considered a 0 priority if priority is equal, most restrictive is with high priority Add SCC $ oc adm policy add-scc-to-user {scc} -z {sa_name} -n {namespace} or more straighward\n$ oc adm policy add-scc-to-user {scc} system:serviceaccount:{namespace}:{sa_name} for example\n$ oc adm policy add-scc-to-user noroot system:serviceaccount:troube:privileged Service Account to DeploymentConfig $ oc set serviceaccount deploymentconfig {deployconfig} {service acccount} it can be expressed shorter\n$ oc set sa dc {dc} {sa} Summary Main concept of Role-based access control, RBAC\nSecret resources allow you to separate sensitive information from application pods\nproject scope extract it for extension (configmap as well) Security context constraints (SCCs) t allowed pod interactions with system resources.\nAbbreviation mcs : multiple category security Components DeploymentConfig Concept Networking keypoints : Troubleshoot it and ingress component\nService Kubernetes service IP == Virtual IP Doesn\u0026rsquo;t allocate any unit/instance A collection of network translation rules 4 types cluster IP node port [older concept] load balancer [older concept] : alway along with cloud providers service name CoreDNS creates two records - A record : resolve FQDN to IP address - SRV record: what port the service uses. - if you use a service exposed TCP 443 through the `https` service in `frontend` namespace - `_443._tcp.https.frontend.svc.cluster.local` Cluster Network Operator can only be configured at installation time\nNetworkType openshiftSDN : 3 types network policy (default) no policy == subnet mode multitenant mode: project-level isolation Pods from different projects cannot communicate with each other unless we create network bridge between them subnet mode (older default, ocp 3.*) flat network Pods can communicate with other Pods whereever their projects Route Ingress in Kubernetes Reverse Proxy When you create route name of service hostname of route Types There\u0026rsquo;re four types:\nservice edge terminated route re-encrypted route passthrough Summary OpenShift implements a software-defined networking (SDN) to manage the network infrastructure Service allow the logical grouping of pods Service acts as load balancer as well Service selects pods by labels Two route : secure and insecure secure : TLS edge passthrough re-encryption Scheduling OpenShift pod scheduler algorithm Filtering nodes. node condition : disk or memory pressure match labels pod resource demands : CPU, Memory and Storage Taint Prioritizing the filtered nodes Affinity Select a fit node can possible create customerized scheduling policies with policy.cfg key\nLabeling on Node Apart from tranditional way of labelling, CLuster administrator can use -L to determine the single label\n$ oc get node -L failure-domain.beta.kubernetes.io/region Labeling Machine Sets Although node labels are persistent, if your OpenShift cluster contains machine sets (created if your cluster was installed using the full stack automation method, IPI), you should add labels to the MachineSets\nThis ensures that new machines will also contains the desired labels when generating new nodes.\nControlling Pod Placement Infrastructure-related Pods run on master nodes DNS Operator OAuth operator API Server Node Selector $ oc edit deployment/myapp spec: ...output omitted... template: metadata: labels: app: myapp spec: nodeSelector: nev: dev containers: - images: quay.io/redhattraining/scaling:v1.0 ...output omitted... the following command accomplishes the same thing\n$ oc patch deployment/myapp --patch \\ \u0026#39;{\u0026#34;spec\u0026#34;:{\u0026#34;template\u0026#34;:{\u0026#34;spec\u0026#34;:{\u0026#34;nodeSelector\u0026#34;:{\u0026#34;env\u0026#34;:\u0026#34;dev\u0026#34;}}}}}\u0026#39; Both commands triggers new deployemnt and new pods scheduled according to the node selector\nDefault Node Selector for a Project default node selector should be configured in the project resource, for example:\ncreate a new project $ oc admin new-project qa --node-selector \u0026#34;env=qa\u0026#34; configure on a existing project $ oc annotate namespace qa \\ openshift.io/node-selector=\u0026#34;env=qa\u0026#34; --overwrite Scaling $ oc scale --replicas 3 deployment/myapp Limiting Resource Usage Resource Requests Used for scheduling, scheduler find a node with sufficient compute resources. indicate that a pod cannot run with less than the specified amount of compute resources. Resource limits how far Pod can consume the resources prevent a pod from using up all compute resources from a node Linux kernel cgroups feature to enforce the resource limits for the pod. Observation the individual resource comsumption for a pod or the sum amount of the resource comsumption\nBy Describe # oc describe node/{node} $ oc describe node ip-10.10.0.0.us-east-1.compute.internal By Node type # oc adm top node # $ oc adm top node -l node-role.kubernetes.io/worker By project $ oc adm top node -n execute-troubleshoot Quality of Service BestEffort first eviction Burstable second evition Guaranteed never evition unless go node down for maintenence Quota Quotas are limitations on the aggregate consumption of resources of any particular project\nTwo kinds Object counts Compute resources Improve stablility of the OpenShift Avoiding unbounded growth of the Etcd database Avoids exhausting other limited software resources, e.g. IP. Some important Note of Quota Best-Effort Node Any Node with resourcequota cannot accommodate any best-effort node\nMultiple Resource Quota in a project Though we can create multiple resourcequota, we cannot overlap the quota items in the same project\nLimit Ranges give range min limits to max limits give deault limits for containers w/o the requests and limits specified Some Pods, System Pods Deployer pod Builder Pod ClusterQuota project-annotation-selector project-label-selector Lookup project scale\n$ oc describe resourcequota cluster span mulitple project\n$ oc describe appliedclusterresourcequotas due to request quota, there\u0026rsquo;s not allowed best effort Pods. It brings the situation to setup default - Limit Range.\nScale Manual Scaling $ oc scale deployment/psql --replicas=3 #or $ oc scale dc/psql --replicas=3 the difference between dc and deployment is that dc adopts replicacontroller whereas deployement adopts replicsets. Basically they are with same mechanism\nAutoscaling Concept utilization Matrix subsystem OCP4 pre-installed OCP3 it\u0026rsquo;s a part of the platform take care of separately Command $ oc autoscale dc/mysql --min=1 --max=5 --cpu-percent=80 Controller by HorizontalPodAutoscalar, HPA Remember that if you want to specify cpu-percent, you must request resources burstable or guaruanteed\nSummary Default pod scheduler spans regions and zones : performance and redundancy.\nPod placement use node selectors w/ labeling nodes.\nResource requests : the minimum amount of resources for scheduling.\nQuotas : restrict the amount consumption of resources a project.\nscales number of replicas of a pod\noc scale for manual oc autoscale for dynamic Scaling an OpenShift Cluster Machine API gives 2 custom resources machine-api operator handle machine-api handle machine two 2 CRD Machineset machine $ oc get clusteroperators $ oc get clusteroperators/machine-api $ oc get -n openshift-machine-api machines $ oc get -n openshift-machine-api machinesets modify Machineset won\u0026rsquo;t affect existing machines only new machine inherit the features analogous to how ReplicaSet treat pods machine-config operator - handle vm or instance - help it become worker node AutoScaling for Cluster concept Cluster-AutoScaler aggregate all machine-autoscaler\nMachine-AutoScaler Usually for the physical partition purpose, like zone\nPerforming Cluster Updates OpenShift 4 architectural let you update your clusters Over-the-Air (OTA). Red Hat provides a distribution system that ensures the best path for updating your cluster and the underlying operating system. There are two distribution channels: fast and stable fast : delivers updates are soon as they are available stable : delivers delayed updates. Red Hat does not support reverting and only supports upgrading Tips List Project $ oc projects Check CRD $ oc get clusteroperators # oc get clusteroperators/{operator} $ oc get clusteroperators/dns # oc get -o yaml {crd}.operator/{name} $ o get -o yaml dns.operator/default Copy Data # oc cp {source} {pod}:{target} $ oc cp data.sql mysql-5cpd:/tmp/ Check Pod/Deployment Mount # oc set volumes deployment/{name} # oc set volumes pod/{name} $ oc set volumnes deployment/mysql Labelling on Node # add new labels $ oc label node node1.us-east-1.compoute.internal env=dev # modify existing labels $ oc label node node1.us-east-1.compute.internal env=dev --overwrite # remove labels $ oc label node node1.us-east-1.compute.internal env- Control Quota $ oc create quota count -n test \\ --hard=services=5,pods=25,replicationcontrollers=17.... $ oc create quota compute -n test \\ --hard=cpu=5,memory=4Gi,limits.cpu=7,limits.memory=8Gi Retry Schdule $ oc rollout retry dc/{name} $ oc rollout latest dc/{name} Security Context Constraints (SCCs) oc adm policy add-scc-to-user SCC (USER| -z SERVICEACCOUNT) [USER....] ","permalink":"https://yc0.github.io/posts/openshift-administration/","summary":"\u003ch1 id=\"describe-openshift-container-platform\"\u003eDescribe OpenShift Container Platform\u003c/h1\u003e\n\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAn application manages Kubernetes resources: Operator\u003c/li\u003e\n\u003cli\u003eAn application manages Kubernetes operators : Operator Lifecycle Manager(OLM)\u003c/li\u003e\n\u003cli\u003eA repo. for discovering and installing operators : Operator Catelog\u003c/li\u003e\n\u003cli\u003eRegular operators that are not managed by the OLM. They are managed by OpenShift Cluster Version Operator : Cluster Operators\n\u003cul\u003e\n\u003cli\u003eOpenShift Cluster Version Operator : First-level operator\u003c/li\u003e\n\u003cli\u003eCluster Operators are called second-level operators\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRed Hat OpenShift Platform is based on Red Hat CoreOS, CRI-O and Kubernetes\u003c/li\u003e\n\u003cli\u003eRHOCP 4 provides a number of services on top of Kubernetes, such as an internal container image registry, storage, networking providers, and centralized logging and monitoring.\u003c/li\u003e\n\u003cli\u003eOperators package applications that manage Kubernetes resources, and the Operator Lifecycle Manager (OLM) handles installation and management of operators.\u003c/li\u003e\n\u003cli\u003eOperatorHub.io is an online catalog for discovering operators.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"installation\"\u003eInstallation\u003c/h1\u003e\n\u003ch2 id=\"ipi\"\u003eIPI\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eFull-Stack Installation\u003c/li\u003e\n\u003cli\u003eOnly this way can fulfil cluster scaling\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://try.openshift.org\"\u003ehttp://try.openshift.org\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eIt does\u0026rsquo;t have to \u003cstrong\u003ebe part of cluster\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"upi\"\u003eUPI\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eUser provisioned Infrastructure for pre-existing environment\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"coreos-and-rhel\"\u003eCoreOS and RHEL\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eControl Panel must run on CoreOS\u003c/li\u003e\n\u003cli\u003eWorkers can run either CoreOS or RHEL\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"installation-configyaml\"\u003eInstallation-config.yaml\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ethe rest of resource domain name following\n\u003ccode\u003e{metadata.name} + {baseDomain}\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003enetwork configuration cannot reconfigure easily after cluster is up and running.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"initial-deployment-process\"\u003eInitial deployment process\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ethere\u0026rsquo;s no much customization\u003c/li\u003e\n\u003cli\u003eUPI mode has to do node certficate when dial to master node (control plane) \u003cstrong\u003eby manual\u003c/strong\u003e whereas IPI has no requirment.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"summary-1\"\u003eSummary\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003etwo main installation methods\n\u003cul\u003e\n\u003cli\u003efull-stack automation\u003c/li\u003e\n\u003cli\u003epre-existing infrastructures.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOpenShift node based on Red Hat Enterprise Linux CoreOS runs very few local services\u003c/li\u003e\n\u003cli\u003eMost of the system run as containers\n\u003cul\u003e\n\u003cli\u003eCRI-O and kubelet\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eTroubleshooting\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eoc get node\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eoc adm top\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eoc adm node-logs\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eoc adm debug\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"trouble-shooting\"\u003eTrouble Shooting\u003c/h1\u003e\n\u003ch2 id=\"oc-adm-node-log\"\u003eoc adm node-log\u003c/h2\u003e\n\u003ch2 id=\"oc-log\"\u003eoc log\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eoc logs \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003epodname\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e --all-containers\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eoc logs \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003epodname\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e -c \u003cspan style=\"color:#f92672\"\u003e{}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"oc-debug\"\u003eoc debug\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ewhat went wrong during POD startup\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eoc debug {pod|deployment} --as-root\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"oc-rsh\"\u003eoc rsh\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ oc exec -it \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003epodname\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e -- \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003ecommand\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003e--options\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ oc exec -it \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003epodname\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e -c \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003econtainer\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e -- \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003ecommand\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003e--options\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eshorter equivalent\u003c/p\u003e","title":"OpenShift Administration"},{"content":"Service Connection Traffice management service mesh traffic management decouples traffic flow and infrastructure scaling Pilot to specify rules for traffic management Pilot and Envoy manage which pods receive traffic Pilot Manages and configures Envoy proxy specify routing rules Enables service discovery, dynamic updates for load balancing, routing tables Envoy Maintains configuration information from Pilot Request Routing Fine-grained approach to identify services by versions Service versions in OpenShift service mesh implemented with OpenShift labels Communication Between Services clients have agnostic of different service versions Envoy intercepts, forwards requests/responses between client and service Routing rules configured with Pilot Header Tags associated with SRC/DEST Weight associated with Version Rule Configuration VirtualService : Defines rules that control how requests for service are routed within service mesh\nDestinationRule : correspond to one or more request destination hosts specified in VirtualService configuration\nMay or may not be same as actual destination workload\nMay not correspond to actual routable service in mesh\nServiceEntry: Enables requests to services outside service mesh\nGateway : Configures load balancer operating at edge of mesh for:\nHTTP/TCP ingress traffic to mesh application Egress traffic to external services Sidecar Configures sidecar proxies attached to application workloads running inside mesh Traffic Splitting Each route rule identifies one or more weighted Versions expressed using labels Conditional Rules Can qualify rules to apply only to requests that match specific condition apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: ratings spec: hosts: - ratings http: - match: - sourceLabels: app: reviews version: v2 - match: - headers: From: exact: webmaster@example.org ","permalink":"https://yc0.github.io/posts/istio-overview/","summary":"\u003ch1 id=\"service-connection\"\u003eService Connection\u003c/h1\u003e\n\u003ch2 id=\"traffice-management\"\u003eTraffice management\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eservice mesh traffic management decouples traffic flow and infrastructure scaling\u003c/li\u003e\n\u003cli\u003ePilot to specify rules for traffic management\u003c/li\u003e\n\u003cli\u003ePilot and Envoy manage which pods receive traffic\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"pilot\"\u003ePilot\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eManages and configures\u003c/strong\u003e Envoy proxy\u003c/li\u003e\n\u003cli\u003especify \u003cstrong\u003erouting rules\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eEnables service \u003cstrong\u003ediscovery\u003c/strong\u003e, \u003cstrong\u003edynamic updates\u003c/strong\u003e for load balancing, routing tables\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"envoy\"\u003eEnvoy\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMaintains configuration information from Pilot\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- more --\u003e\n\u003ch2 id=\"request-routing\"\u003eRequest Routing\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eFine-grained approach to identify services by versions\u003c/li\u003e\n\u003cli\u003eService versions in OpenShift service mesh implemented with \u003cstrong\u003eOpenShift labels\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"communication-between-services\"\u003eCommunication Between Services\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eclients have \u003cstrong\u003eagnostic\u003c/strong\u003e of different service versions\u003c/li\u003e\n\u003cli\u003eEnvoy \u003cstrong\u003eintercepts\u003c/strong\u003e, forwards requests/responses between client and service\u003c/li\u003e\n\u003cli\u003eRouting rules \u003cstrong\u003econfigured with Pilot\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eHeader\u003c/li\u003e\n\u003cli\u003eTags associated with SRC/DEST\u003c/li\u003e\n\u003cli\u003eWeight associated with Version\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"rule-configuration\"\u003eRule Configuration\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eVirtualService : Defines rules that control how requests for service are routed within service mesh\u003c/p\u003e","title":"Istio Overview"},{"content":"Quick Overview kubernetes .io Getting started create pod kubectl run --generator=run-pod/v1\nfor example\nkubectl run --generator=run-pod/v1 bee --image=nginx\nalias cheat sheet https://kubernetes.io/docs/reference/kubectl/cheatsheet/ other alias k=\u0026#39;kubectl -n $ns\u0026#39; alias kdr=\u0026#39;kubectl run -n $ns -o yaml --dry-run\u0026#39; alias kpr=\u0026#39;kubectl run --generator=run-pod/ v1 -n $ns -o yaml --dry-run\u0026#39; Shell Get rid of the first line and recliam first column $ awk \u0026#39;NR!=1{print $1}\u0026#39; file Read follow line regarding to certain word #grep -A{lines} {keyword} $ grep -A3 \u0026#39;Labels\u0026#39; Execution Tips Check Network Connection Netcat example # kubectl exec -it {podname} -- sh $ nc -z -v -w1 {target} {port} VIM Tips Auto indent and tab se sts=2 sw=2 ai et set nu rnu 與自動縮進相關的變數表 變數名 縮寫 含義 (no)autoindent ai 自動縮進，即為新行自動添加與當前行同等的縮進 (no)cindent ci 類似C語言程序的縮進 (no)smartindent si 基於autoindent的一些改進 與TAB相關的變數表 變數名 縮寫 含義 tabstop=X ts 編輯時一個TAB字元佔多少個空格的位置 shiftwidth=X sw 使用每層縮進的空格數 (no)expandtab (no)et 是否將輸入的TAB自動展開成空格。開啟後要輸入TAB，需要Ctrl-V softtabstop=X sts 方便在開啟了et後使用退格（backspace）鍵，每次退格將刪除X個空格 (no)smarttab (no)sta 開啟時，在行首按TAB將加入sw個空格，否則加入ts個空格 ","permalink":"https://yc0.github.io/posts/kubernetes-scratch/","summary":"\u003ch2 id=\"quick-overview\"\u003eQuick Overview\u003c/h2\u003e\n\u003ch3 id=\"kubernetes-io\"\u003ekubernetes .io\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#-em-deployment-em-\"\u003eGetting started\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"create-pod\"\u003ecreate pod\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003ekubectl run --generator=run-pod/v1\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003efor example\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ekubectl run --generator=run-pod/v1 bee --image=nginx\u003c/code\u003e\u003c/p\u003e\n\u003ch3 id=\"alias\"\u003ealias\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003echeat sheet\n\u003ccode\u003ehttps://kubernetes.io/docs/reference/kubectl/cheatsheet/\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"other\"\u003eother\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ealias k=\u0026#39;kubectl -n $ns\u0026#39;\n\nalias kdr=\u0026#39;kubectl run -n $ns -o yaml \n--dry-run\u0026#39;\n\nalias kpr=\u0026#39;kubectl run --generator=run-pod/ v1 -n $ns -o yaml --dry-run\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"shell\"\u003eShell\u003c/h3\u003e\n\u003ch4 id=\"get-rid-of-the-first-line-and-recliam-first-column\"\u003eGet rid of the first line and recliam first column\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ awk \u0026#39;NR!=1{print $1}\u0026#39; file\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"read-follow-line-regarding-to-certain-word\"\u003eRead follow line regarding to certain word\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#grep -A{lines} {keyword}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ grep -A3 \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Labels\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"execution-tips\"\u003eExecution Tips\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eCheck Network Connection\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://blog.gtwang.org/linux/linux-utility-netcat-examples/\"\u003eNetcat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eexample\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# kubectl exec -it {podname} -- sh\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ nc -z -v -w1 \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003etarget\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e{\u003c/span\u003eport\u003cspan style=\"color:#f92672\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"vim-tips\"\u003eVIM Tips\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eAuto indent and tab\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ese sts\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e sw\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e ai et\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eset nu rnu\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch5 id=\"與自動縮進相關的變數表\"\u003e與自動縮進相關的變數表\u003c/h5\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e變數名\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e縮寫\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e含義\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e(no)autoindent\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eai\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e自動縮進，即為新行自動添加與當前行同等的縮進\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e(no)cindent\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003eci\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e類似C語言程序的縮進\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e(no)smartindent\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003esi\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e基於autoindent的一些改進\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch5 id=\"與tab相關的變數表\"\u003e與TAB相關的變數表\u003c/h5\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e變數名\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e縮寫\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e含義\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003etabstop=X\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003ets\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e編輯時一個TAB字元佔多少個空格的位置\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eshiftwidth=X\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003esw\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e使用每層縮進的空格數\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e(no)expandtab\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e(no)et\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e是否將輸入的TAB自動展開成空格。開啟後要輸入TAB，需要Ctrl-V\u003cTAB\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003esofttabstop=X\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003ests\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e方便在開啟了et後使用退格（backspace）鍵，每次退格將刪除X個空格\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e(no)smarttab\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e(no)sta\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e開啟時，在行首按TAB將加入sw個空格，否則加入ts個空格\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e","title":"kubernetes scratch"},{"content":"C++ Task Scheduler The requirment needs for tasks scheduled once and repetitive tasks, and should stop and clean itself up gracefully on destruction even while running. DO NOT care for parallelism: tasks that should run in their own threads should manage it. It had to accept lambdas for simplicity.\nAlthough there\u0026rsquo;re Boost or POCO, we try to be interested in writing it myself.\nImplmentation #include \u0026lt;functional\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026lt;future\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;memory\u0026gt; struct function_timer { std::function\u0026lt;void()\u0026gt; func; std::chrono::system_clock::time_point time; function_timer() { } function_timer(std::function\u0026lt;void()\u0026gt;\u0026amp;\u0026amp; f, std::chrono::system_clock::time_point\u0026amp; t) : func(f), time(t) { } //Note: we want our priority_queue to be ordered in terms of //smallest time to largest, hence the \u0026gt; in operator\u0026lt;. This isn\u0026#39;t good //practice - it should be a separate struct - but I\u0026#39;ve done this for brevity. bool operator\u0026lt;(const function_timer\u0026amp; rhs) const { return time \u0026gt; rhs.time; } void get() { func(); } }; class Scheduler { private: std::priority_queue\u0026lt;function_timer\u0026gt; tasks; std::unique_ptr\u0026lt;std::thread\u0026gt; thread; bool go_on; Scheduler\u0026amp; operator=(const Scheduler\u0026amp; rhs) = delete; Scheduler(const Scheduler\u0026amp; rhs) = delete; public: Scheduler() :go_on(true), thread(new std::thread([this]() { ThreadLoop(); })) { } ~Scheduler() { go_on = false; thread-\u0026gt;join(); } void ThreadLoop() { while(go_on) { auto now = std::chrono::system_clock::now(); while(!tasks.empty() \u0026amp;\u0026amp; tasks.top().time \u0026lt;= now) { function_timer\u0026amp; f = tasks.top(); f.get(); tasks.pop(); } if(tasks.empty()) { std::this_thread::sleep_for(std::chrono::milliseconds(100)); } else { std::this_thread::sleep_for(tasks.top().time - std::chrono::system_clock::now()); } } } void ScheduleAt(std::chrono::system_clock::time_point\u0026amp; time, std::function\u0026lt;void()\u0026gt;\u0026amp;\u0026amp; func) { tasks.push(function_timer(std::move(func), time)); } void ScheduleEvery(std::chrono::system_clock::duration interval, std::function\u0026lt;void()\u0026gt; func) { std::function\u0026lt;void()\u0026gt; waitFunc = [this,interval,func]() { func(); this-\u0026gt;ScheduleEvery(interval, func); }; ScheduleAt(std::chrono::system_clock::now() + interval, std::move(waitFunc)); } }; ","permalink":"https://yc0.github.io/posts/c-task-scheduler/","summary":"\u003ch1 id=\"c-task-scheduler\"\u003eC++ Task Scheduler\u003c/h1\u003e\n\u003cp\u003eThe requirment needs for tasks scheduled once and repetitive tasks, and should stop and clean itself up gracefully on destruction even while running.\nDO NOT care for parallelism: tasks that should run in their own threads should manage it. It had to accept lambdas for simplicity.\u003c/p\u003e\n\u003cp\u003eAlthough there\u0026rsquo;re Boost or POCO, we try to be interested in writing it myself.\u003c/p\u003e\n\u003ch2 id=\"implmentation\"\u003eImplmentation\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-c++\" data-lang=\"c++\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#include\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e\u0026lt;functional\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#include\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e\u0026lt;chrono\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#include\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e\u0026lt;future\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#include\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e\u0026lt;queue\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#include\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e\u0026lt;thread\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#include\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e\u0026lt;memory\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#75715e\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003estruct\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003efunction_timer\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e{\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003efunction\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e()\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e func;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003echrono\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003esystem_clock\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003etime_point time;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    function_timer()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    { }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    function_timer(std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003efunction\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e()\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u0026amp;\u0026amp;\u003c/span\u003e f, std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003echrono\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003esystem_clock\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003etime_point\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e t)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003e func(f), \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e          time(t)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    { }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e//Note: we want our priority_queue to be ordered in terms of\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e    \u003cspan style=\"color:#75715e\"\u003e//smallest time to largest, hence the \u0026gt; in operator\u0026lt;. This isn\u0026#39;t good\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e    \u003cspan style=\"color:#75715e\"\u003e//practice - it should be a separate struct -  but I\u0026#39;ve done this for brevity.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e    \u003cspan style=\"color:#66d9ef\"\u003ebool\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eoperator\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e(\u003cspan style=\"color:#66d9ef\"\u003econst\u003c/span\u003e function_timer\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e rhs) \u003cspan style=\"color:#66d9ef\"\u003econst\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e time \u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e rhs.time;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eget\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        func();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e};\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eclass\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eScheduler\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e{\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eprivate\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003epriority_queue\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003efunction_timer\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e tasks;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003eunique_ptr\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003estd\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ethread\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003ethread\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003ebool\u003c/span\u003e go_on;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    Scheduler\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eoperator\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(\u003cspan style=\"color:#66d9ef\"\u003econst\u003c/span\u003e Scheduler\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e rhs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003edelete\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    Scheduler(\u003cspan style=\"color:#66d9ef\"\u003econst\u003c/span\u003e Scheduler\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e rhs) \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003edelete\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003epublic\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    Scheduler()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#f92672\"\u003e:\u003c/span\u003ego_on(true),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ethread\u003c/span\u003e(\u003cspan style=\"color:#66d9ef\"\u003enew\u003c/span\u003e std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003ethread\u003c/span\u003e([\u003cspan style=\"color:#66d9ef\"\u003ethis\u003c/span\u003e]() { ThreadLoop(); }))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    { }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003e~\u003c/span\u003eScheduler()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        go_on \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e false;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ethread\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003ejoin();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eThreadLoop\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ewhile\u003c/span\u003e(go_on)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003eauto\u003c/span\u003e now \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003echrono\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003esystem_clock\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003enow();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003ewhile\u003c/span\u003e(\u003cspan style=\"color:#f92672\"\u003e!\u003c/span\u003etasks.empty() \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e tasks.top().time \u003cspan style=\"color:#f92672\"\u003e\u0026lt;=\u003c/span\u003e now) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                function_timer\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e f \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tasks.top();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                f.get();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                tasks.pop();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e(tasks.empty()) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003ethis_thread\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003esleep_for(std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003echrono\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003emilliseconds(\u003cspan style=\"color:#ae81ff\"\u003e100\u003c/span\u003e));\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            } \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003ethis_thread\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003esleep_for(tasks.top().time \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003echrono\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003esystem_clock\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003enow());\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eScheduleAt\u003c/span\u003e(std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003echrono\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003esystem_clock\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003etime_point\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e time, std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003efunction\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e()\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u0026amp;\u0026amp;\u003c/span\u003e func)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        tasks.push(function_timer(std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003emove(func), time));\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eScheduleEvery\u003c/span\u003e(std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003echrono\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003esystem_clock\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003eduration interval, std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003efunction\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e()\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e func)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003efunction\u003cspan style=\"color:#f92672\"\u003e\u0026lt;\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e()\u003cspan style=\"color:#f92672\"\u003e\u0026gt;\u003c/span\u003e waitFunc \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [\u003cspan style=\"color:#66d9ef\"\u003ethis\u003c/span\u003e,interval,func]()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            { \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                func();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#66d9ef\"\u003ethis\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003eScheduleEvery(interval, func);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            };\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ScheduleAt(std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003echrono\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003esystem_clock\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003enow() \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e interval, std\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003emove(waitFunc));\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e};\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"C++ Task Scheduler"},{"content":"Comments Filtering System Design Amazon comments filtering system. Use UML to design the classes.\nAt First Glance Class encapsulating a \u0026lsquo;comment\u0026rsquo; Main Filter abstract class Different types of Filter class like AbusiveContentFilter, Special Characters Filter, Duplicate Content Filter etc. A top \u0026lsquo;Filters\u0026rsquo; class containing a method \u0026lsquo;applyFilters\u0026rsquo; where filters can be passed as an array of \u0026lsquo;Filter\u0026rsquo; objects. On application of these filters the comment would be cleaned and a return object of type \u0026lsquo;ResultComment\u0026rsquo; with boolean attributes like isCommentOk\nImplmentation #include \u0026lt;unordered_set\u0026gt; #include \u0026lt;assert.h\u0026gt; using namespace std; class Rule { private: unordered_set\u0026lt;string\u0026gt; words; public: virtual string valid(string s) = 0; unordered_set\u0026lt;string\u0026gt; getWords() { return words; } void addWord(string word) { words.insert(word); } bool match(string c) { return words.count(c) == 1; } vector\u0026lt;string\u0026gt; split(string str, string pattern) { string::size_type pos; vector\u0026lt;std::string\u0026gt; result; str += pattern; int size = str.size(); for (int i = 0; i \u0026lt; size; i++) { pos = str.find(pattern, i); if (pos \u0026lt; size) { std::string s = str.substr(i, pos - i); result.push_back(s); i = pos + pattern.size() - 1; } } return result; } }; class AdRule : public Rule { public: string valid(string s) { string r = \u0026#34;\u0026#34;; auto words = split(s, \u0026#34; \u0026#34;); for (auto word : words) { if (!match(word)) { r = r + \u0026#34; \u0026#34; + word; } else { r += \u0026#34; *\u0026#34;; } } return r; } }; class PornRule : public Rule { public: string valid(string s) { string r = \u0026#34;\u0026#34;; auto words = split(s, \u0026#34; \u0026#34;); for (auto word : words) { if (match(word)) { return \u0026#34;\u0026#34;; } else { r = r + \u0026#34; \u0026#34; + word; } } return r; } }; class Filter { private: vector\u0026lt;Rule *\u0026gt; rules; public: void addRule(Rule *rule) { rules.push_back(rule); } string valid(string s) { for (Rule *rule : rules) { s = rule-\u0026gt;valid(s); } return s; } }; class Comment { private: string content; Filter *filter; public: Comment(string s, Filter *f) : content(s), filter(f) { } string valid() { return filter-\u0026gt;valid(content); } }; int main() { AdRule *adRule = new AdRule(); adRule-\u0026gt;addWord(\u0026#34;ad\u0026#34;); adRule-\u0026gt;addWord(\u0026#34;buy\u0026#34;); PornRule *pornRule = new PornRule(); pornRule-\u0026gt;addWord(\u0026#34;porn\u0026#34;); pornRule-\u0026gt;addWord(\u0026#34;sex\u0026#34;); Filter *filter = new Filter(); filter-\u0026gt;addRule(adRule); filter-\u0026gt;addRule(pornRule); Comment *c1 = new Comment(\u0026#34;this is a ad\u0026#34;, filter); assert(c1-\u0026gt;valid() == \u0026#34; this is a *\u0026#34;); Comment *c2 = new Comment(\u0026#34;this is a porn\u0026#34;, filter); assert(c2-\u0026gt;valid() == \u0026#34;\u0026#34;); return 0; } ","permalink":"https://yc0.github.io/posts/design-amazon-comments-filtering-system/","summary":"\u003ch1 id=\"comments-filtering-system\"\u003eComments Filtering System\u003c/h1\u003e\n\u003cp\u003eDesign Amazon comments filtering system. Use UML to design the classes.\u003c/p\u003e\n\u003c!-- more --\u003e\n\u003ch2 id=\"at-first-glance\"\u003eAt First Glance\u003c/h2\u003e\n\u003cp\u003eClass encapsulating a \u0026lsquo;comment\u0026rsquo;\nMain Filter abstract class\nDifferent types of Filter class like AbusiveContentFilter, Special Characters Filter, Duplicate Content Filter etc.\nA top \u0026lsquo;Filters\u0026rsquo; class containing a method \u0026lsquo;applyFilters\u0026rsquo; where filters can be passed as an array of \u0026lsquo;Filter\u0026rsquo; objects.\nOn application of these filters the comment would be cleaned and a return object of type \u0026lsquo;ResultComment\u0026rsquo; with boolean attributes like isCommentOk\u003c/p\u003e","title":"Design Amazon comments filtering system"},{"content":"Use Exception Instead of Error Code try/catch 會混淆結構，最好的做法，是將內容從try/catch中抽離出來到一個functions如下：\npublic void delete(Page page) { try { deletePageAndAllReference(pages); } catch (Exception e) { logError(e); } } private void deletePageAndAllReference(Page page) throws Exception { deletePage(page); registry.deleteReference(page.name); configKeys.deleteKey(page.name.makeKey()); } private void logError(Exception e) { logger.log(e.getMessage()); } In the above, the delete function is all about error processing. It is easy to understand and then ignore. The deletePageAndAllReferences function is all about the processes of fully deleting a page. Error handling can be ignored. This provides a nice separation that makes the code easier to understand and modify.\n","permalink":"https://yc0.github.io/posts/use-exception-instead-of-error-code/","summary":"\u003ch2 id=\"use-exception-instead-of-error-code\"\u003eUse Exception Instead of Error Code\u003c/h2\u003e\n\u003cp\u003etry/catch 會混淆結構，最好的做法，是將內容從try/catch中抽離出來到一個functions如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003epublic\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003edelete\u003c/span\u003e(Page page) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003etry\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        deletePageAndAllReference(pages);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    } \u003cspan style=\"color:#66d9ef\"\u003ecatch\u003c/span\u003e (Exception e) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        logError(e);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eprivate\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003edeletePageAndAllReference\u003c/span\u003e(Page page) \u003cspan style=\"color:#66d9ef\"\u003ethrows\u003c/span\u003e Exception {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    deletePage(page);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    registry.\u003cspan style=\"color:#a6e22e\"\u003edeleteReference\u003c/span\u003e(page.\u003cspan style=\"color:#a6e22e\"\u003ename\u003c/span\u003e);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    configKeys.\u003cspan style=\"color:#a6e22e\"\u003edeleteKey\u003c/span\u003e(page.\u003cspan style=\"color:#a6e22e\"\u003ename\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003emakeKey\u003c/span\u003e());  \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eprivate\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003elogError\u003c/span\u003e(Exception e) {    \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    logger.\u003cspan style=\"color:#a6e22e\"\u003elog\u003c/span\u003e(e.\u003cspan style=\"color:#a6e22e\"\u003egetMessage\u003c/span\u003e());\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e} \n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eIn the above, the delete function is all about error processing. It is easy to understand and then ignore. The deletePageAndAllReferences function is all about the processes of fully deleting a page. Error handling can be ignored. This provides a nice separation that makes the code easier to understand and modify.\u003c/p\u003e","title":"Use exception instead of error code"},{"content":"LSM Design Overview The LSM stores data in three distinct data structures:\nThe shared-memory region. This may actually be allocated in either shared or heap memory\nThe log file. A circular log file that provides a persistent backup of the contents of the in-memory tree and any other data that has not yet been synced to disk.\nThe database file. A database file consists of an 8KB header and a body. The body contains zero or more \u0026quot;sorted runs\u0026quot; - arrays of key-value pairs sorted by key.\nTo query a database, the contents of the in-memory tree must be merged with the contents of each sorted run in the database file. Entries from newer sorted runs are favoured over old (for the purposes of merging, the in-memory tree contains the newest data).\nIn summary LSM embedded database software stores data in three distinct data structures:\nThe shared-memory region. This may actually be allocated in either shared or heap memory, depending on whether LSM is running in multi (the default) or single process mode. Either way, the shared-memory region contains volatile data that is shared at run-time between database clients. Similar to the *-shm file used by SQLite in WAL mode. As well as various fixed-size fields, the shared-memory region contains the \u0026lsquo;in-memory tree\u0026rsquo;. The in-memory tree is an append-only red-black tree structure used to stage user data that has not yet flushed into the database file by the system. Under normal circumstances, the in-memory tree is not allowed to grow very large.\nThe log file. A circular log file that provides a persistent backup of the contents of the in-memory tree and any other data that has not yet been synced to disk. The log-file is not used for rollback (like an SQLite journal file) or to store data that is retrieved at runtime by database clients (like an SQLite WAL file). Its only purpose is to provide robustness.\nThe database file. A database file consists of an 8KB header and a body. The body contains zero or more \u0026ldquo;sorted runs\u0026rdquo; - arrays of key-value pairs sorted by key.\nTo query a database, the contents of the in-memory tree must be merged with the contents of each sorted run in the database file. Entries from newer sorted runs are favoured over old (for the purposes of merging, the in-memory tree contains the newest data).\nWhen an application writes to the database, the new data is written to the in-memory tree. Once the in-memory tree has grown large enough, its contents are written into the database file as a new sorted run. To reduce the number of sorted runs in the database file, chronologically adjacent sorted runs may be merged together into a single run, either automatically or on demand.\nLocks Read/write (shared/exclusive) file locks are used to control concurrent access. LSM uses the following \u0026ldquo;locking regions\u0026rdquo;. Each locking region may be locked and unlocked separately.\nTypes 內容 DMS1 This locking region is used to serialize all connection and disconnection operations performed by read-write database connections. An EXCLUSIVE lock is taken for the duration of all such operations.　Additionally, read-only connections take a SHARED lock on this locking region while attempting to connect to a database. This ensures that a read-only connection does not attempt to connect to the database while a read-write clients connection or disconnection operation is ongoing. DMS2 Read-write connections hold a SHARED lock on this locking region for as long as they are connected to the database. DMS3 Read-only connections hold a SHARED lock on this locking region for as long as they are connected to the database. ｜RWCLIENT(n) There are a total of 16 RWCLIENT locking regions. After a read-write client connects to the database it attempts to find a free RWCLIENT locking slot to take an EXCLUSIVE lock on. If it cannot find one, this is not an error. If it can, then the lock is held for as long as the read-write client is connected to the database for.\nThe sole purpose of these locks is that they allow a read-only client to detect whether or not there exists at least one read-write client connected to the database. Of course if large numbers of read-write clients connect and disconnect from the system in an inconvenient order the system may enter a state where there exists one or more connected read-write clients but none of them hold a RWCLIENT lock. This is not important - if a read-only client fails to detect that the system has read-write clients it may be less efficient, but will not malfunction. WRITER A database client holds an EXCLUSIVE lock on this locking region while writing data to the database. Outside of recovery, only clients holding this lock may modify the contents of the in-memory b-tree. Holding this lock is synonymous with having an open write transaction on the database. WORKER A database client holds an EXCLUSIVE lock on this locking region while performing database work (writing data into the body of the database file). CHECKPOINTER A database client holds an EXCLUSIVE lock on this locking region while performing a checkpoint (syncing the database file and writing to the database header). ROTRANS A read-only database client holds a SHARED lock on this locking region while reading from a non-live database system. READER(n) There are a total of 6 READER locking regions. Unless it is a read-only client reading from a non-live database, a client holds a SHARED lock on one of these while it has an open read transaction. Each READER lock is associated with a pair of id values identifying the regions of the in-memory tree and database file that may be read by clients holding such SHARED locks. Database Connect and Disconnect Operations ","permalink":"https://yc0.github.io/posts/design-lsm-database/","summary":"\u003ch2 id=\"lsm-design-overview\"\u003eLSM Design Overview\u003c/h2\u003e\n\u003cp\u003eThe LSM stores data in three distinct data structures:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe \u003ccode\u003eshared-memory region\u003c/code\u003e. This may actually be allocated in either shared or heap memory\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe log file. A circular log file that provides a persistent backup of the contents of the in-memory tree and any other data that has \u003ccode\u003enot yet been synced to disk\u003c/code\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe database file. A database file consists of an 8KB \u003ccode\u003eheader and a body\u003c/code\u003e. The body contains \u003ccode\u003ezero or more \u0026quot;sorted runs\u0026quot;\u003c/code\u003e - arrays of key-value pairs sorted by key.\u003c/p\u003e","title":"Design LSM Database"},{"content":"Design a locker To monitor the process of how to put the package into a right locker. and one locker for one package. your package and locker have different size, you need to make sure the locker size \u0026gt; package.\nit is just parking lot alike. We can directly manipulate the same concept, or just use the same pattern from Parking Lot Objects Locker Location Package User Order Shipment Work flows Amazon warehouse packages Orders into a Shipment with one or more Packages. Insert created Package(s) into a database and associate them with a Shipment. Associate Shipment with Order, Associate Order with User. Guarantee that the length, width, and height of each Package cannot exceed the largest Locker\u0026rsquo;s length, width, and height. (Closest Locker Problem) Find closest Location of lockers to the Package\u0026rsquo;s destination Location. Check the valid volumns; check that the Location has a volume of Locker spaces greater than or equal to the Package volume (we only need to check volume because step 3 constrains the dimensions). If not, find second closest Locker Location, and so on and so forth. (Fitting Problem) Lockers have a set number of sizes (say small, medium, and large). Now, design an algorithm to fit Packages volume into Locker volume, so that minimum amount of Lockers are used. This is easily imagined as a recursive algorithm where you continuously solve for the remaining Packages until the Packages are all fit into Lockers. Each time you fit a package, you return a list of available boxes (remaining spaces in the locker in terms of boxes for that single Locker). If there are no boxes that fit the remaining packages, look for another Locker for the rest of the packages. This method will return the list of Lockers used for the Shipment. Once we know the Packages can be stored at a Locker Location, return the used Locker\u0026rsquo;s Locker IDs and Password to the user (delivery person, recipient, etc). ","permalink":"https://yc0.github.io/posts/design-a-locker/","summary":"\u003ch2 id=\"design-a-locker\"\u003eDesign a locker\u003c/h2\u003e\n\u003cp\u003eTo monitor the process of how to put the package into a right locker. and one locker for one package. your package and locker have different size, you need to make sure the locker size \u0026gt; package.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eit is just parking lot alike. We can directly manipulate the same concept, or just use the same pattern from Parking Lot\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"objects\"\u003eObjects\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eLocker\u003c/li\u003e\n\u003cli\u003eLocation\u003c/li\u003e\n\u003cli\u003ePackage\u003c/li\u003e\n\u003cli\u003eUser\u003c/li\u003e\n\u003cli\u003eOrder\u003c/li\u003e\n\u003cli\u003eShipment\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"work-flows\"\u003eWork flows\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eAmazon warehouse packages Orders into a Shipment with one or more Packages.\u003c/li\u003e\n\u003cli\u003eInsert created Package(s) into a database and associate them with a Shipment.\u003c/li\u003e\n\u003cli\u003eAssociate Shipment with Order, Associate Order with User.\u003c/li\u003e\n\u003cli\u003eGuarantee that the length, width, and height of each Package cannot exceed the largest Locker\u0026rsquo;s length, width, and height.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e(Closest Locker Problem)\u003c/code\u003e Find closest Location of lockers to the Package\u0026rsquo;s destination Location.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eCheck the valid volumns\u003c/code\u003e; check that the Location has a volume of Locker spaces greater than or equal to the Package volume (we only need to check volume because step 3 constrains the dimensions). If not, find second closest Locker Location, and so on and so forth.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e(Fitting Problem)\u003c/code\u003e Lockers have a set number of sizes (say small, medium, and large). Now, design an algorithm to fit Packages volume into Locker volume, so that minimum amount of Lockers are used. This is easily imagined as a recursive algorithm where you continuously solve for the remaining Packages until the Packages are all fit into Lockers. Each time you fit a package, you return a list of available boxes (remaining spaces in the locker in terms of boxes for that single Locker). If there are no boxes that fit the remaining packages, look for another Locker for the rest of the packages. This method will return the list of Lockers used for the Shipment.\u003c/li\u003e\n\u003cli\u003eOnce we know the Packages can be stored at a Locker Location, return the used Locker\u0026rsquo;s Locker IDs and Password to the user (delivery person, recipient, etc).\u003c/li\u003e\n\u003c/ol\u003e","title":"Design a locker"},{"content":"Design a Vending Machine Add items to the vending machine in fixed number of slots Payment using card or cash Select items to dispense Think of all objects in reality Think of all the Real objects :\nCustomer Product/Item (Product/Item Type (softdrink, cold coffee, cold tea)) Payment (transaction) Cash or Card (Credit/Debit Card) Buttom, Item Code Work Flow Think about work flow :\nCustomer select an item (by entering the code A5) Customer is presented by item price Customer chooses to pay or cancels Customer can add Card and do payment Payment goes through (Item is despense) else add Card info again Alernatively, Customer adds bills cal and return the change and despense the item Design patttern take those pattern into accout\nCommand/Stragegy pattern Singleton for Vending machine instance Fascade pattern for charing for multiple item Reference Design Actually, I do not like this implementation. But I put here just for reference now.\nstruct Product { virtual float getPrice() = 0; }; struct Water : Product { float getPrice() override {return 1.0;} }; struct Coke : Product { float getPrice() override {return 2.0;} }; struct Payment { virtual float checkout(Product *p) = 0; }; struct CardPayment : Payment { float checkout(Product *p) override { return p-\u0026gt;getPrice() * 0.8; } }; struct CashPayment : Payment { float checkout(Product *p) override { return p-\u0026gt;getPrice() * 1; } }; class VendingMachine { private: unordered_map\u0026lt;string, Product *\u0026gt; slots; int capacity; int pay; public: VendingMachine(int cap) : capacity(cap){}; bool addProduct(string idx, Product *p) { if (slots.size() \u0026gt;= capacity) { return false; } slots.insert({idx, p}); return true; } Product *order(string idx) { auto result = slots[idx]; if (result) slots.erase(idx); return result; } float checkout(vector\u0026lt;Product *\u0026gt;\u0026amp; prod, Payment *pay) { float total = 0; for (auto p : prod) total += pay-\u0026gt;checkout(p); return total; } }; class Customer { private: VendingMachine *vm; vector\u0026lt;Product *\u0026gt; cart; public: Customer(VendingMachine *v) : vm(v) {} bool select(string idx) { Product *p = vm-\u0026gt;order(idx); if (p) { cart.push_back(p); return true; } return false; } float checkout(Payment *payment) { return vm-\u0026gt;checkout(cart, payment); } }; int main() { auto w1 = new Water(); auto w2 = new Water(); auto c1 = new Coke(); auto c2 = new Coke(); auto vm = new VendingMachine(5); vm-\u0026gt;addProduct(\u0026#34;A1\u0026#34;, w1); vm-\u0026gt;addProduct(\u0026#34;A2\u0026#34;, w2); vm-\u0026gt;addProduct(\u0026#34;A3\u0026#34;, c1); vm-\u0026gt;addProduct(\u0026#34;A4\u0026#34;, c2); Customer *customer = new Customer(vm); customer-\u0026gt;select(\u0026#34;A1\u0026#34;); customer-\u0026gt;select(\u0026#34;A2\u0026#34;); auto card = new CardPayment(); assert(abs(customer-\u0026gt;checkout(card) - 1.6) \u0026lt; 1e-6); return 0; } ","permalink":"https://yc0.github.io/posts/design-a-vending-machine/","summary":"\u003ch2 id=\"design-a-vending-machine\"\u003eDesign a Vending Machine\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAdd items to the vending machine in fixed number of slots\u003c/li\u003e\n\u003cli\u003ePayment using card or cash\u003c/li\u003e\n\u003cli\u003eSelect items to dispense\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"think-of-all-objects-in-reality\"\u003eThink of all objects in reality\u003c/h3\u003e\n\u003cp\u003eThink of all the Real objects :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCustomer\u003c/li\u003e\n\u003cli\u003eProduct/Item (Product/Item Type (softdrink, cold coffee, cold tea))\u003c/li\u003e\n\u003cli\u003ePayment (transaction)\u003c/li\u003e\n\u003cli\u003eCash or Card (Credit/Debit Card)\u003c/li\u003e\n\u003cli\u003eButtom,\u003c/li\u003e\n\u003cli\u003eItem Code\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"work-flow\"\u003eWork Flow\u003c/h3\u003e\n\u003cp\u003eThink about work flow :\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCustomer \u003ccode\u003eselect an item\u003c/code\u003e (by entering the code A5)\u003c/li\u003e\n\u003cli\u003eCustomer is \u003ccode\u003epresented by item price\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eCustomer \u003ccode\u003echooses to pay or cancels\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eCustomer can add Card and do payment\u003c/li\u003e\n\u003cli\u003ePayment goes through (Item is despense) else add Card info again\u003c/li\u003e\n\u003cli\u003eAlernatively, Customer \u003ccode\u003eadds bills cal\u003c/code\u003e and \u003ccode\u003ereturn the change\u003c/code\u003e and \u003ccode\u003edespense the item\u003c/code\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"design-patttern\"\u003eDesign patttern\u003c/h3\u003e\n\u003cp\u003etake those pattern into accout\u003c/p\u003e","title":"Design a Vending Machine"},{"content":"Configuration management system Design a configuration management system\nUser should be able to add configuration User should be able to delete configuration User should be able to search for configuration User should be able to subscribe to Configuration So that any updates in configuration will gets notfied to user Clarify We want to design a system to persist configurations that can be used by other systems. Configurations will be managed through an internal portal and will be editable only by the user who created them but can be read by any system through a RESTful API. In addition to CRUD (creation, read, updates and deletions) an user can search for configurations and can subscribe to them to receive notifications every time there\u0026rsquo;s a change.\nThis is how I\u0026rsquo;d go about it (since I don\u0026rsquo;t have an interviewer to ask questions to, these numbers are made up):\nAssumptions Let\u0026rsquo;s say we have 500M total users and 50M daily active users There are 1M new configurations created every day on average We get 100M reads of the configurations every day on average Updates are infrequent but they happen: 10k a day on average Deletions are even more infrequent: 5k a day on average Each active user performs 2 searches a day on average 5k subscriptions every day, 0.5k unsubscriptions a day on average Configurations are JSON files that are 1kb in size on average Following the CAP theorem, we can argue that we are interested in an AP system (highly available, partitioned and eventually consistent). With this data, I\u0026rsquo;d do some back-of-the-envelope math:\nTraffic: Calculate the read TPS and write TPS. Bandwidth: download and upload bandwidth necessary to serve the content Memory: how much memory we are going to need to store 5 and 10 years of configurations * (see below for this) Cache: following the 80/20 rule, calculate how much memory we need to store 20% of daily configurations * (see below for this) To do number 3 and 4, we should sketch the models:\nConfiguration Table:\nConfigurationID ConfigurationName OwnerID ConfigurationURI CreationTimestamp We should estimate the length in bytes of the configuration ID to be able to hold 10 years of IDs. Same for ownerID. Now that we\u0026rsquo;ve done some math, we probably found out the following:\nThe system is VERY read heavy: Probably a good approach would be to have master write DBs where the changes are propagated to the slave read DBs. Cache will benefit us immensely. Talk about eviction strategies. The TPS will help us figure out how many web servers we need. The memory will probably tell us that we need sharding. Discuss here sharding strategies and No SQL vs SQL databases. Quickly sketch the APIs of the system and their parameters. At least we need the following APIs:\nCreateConfiguration UpdateConfiguration DeleteConfiguration ReadConfiguration SearchConfigurations SubscribeToConfiguration UnsubscribeFromConfiguration After this, draw a HIGH LEVEL diagram (without scaling, load balancing, redundancy, cache etc.) to trace a request for each API:\n|-----\u0026gt; IndexService --------v User --\u0026gt; Web Server --\u0026gt; ConfigurationService --\u0026gt; Database |-----\u0026gt; Cloud Storage After that, we can move on to a detailed design:\nUser --\u0026gt; LoadBalancer --\u0026gt; [WebServer1, WebServer2, ...] --\u0026gt; Load Balancer --\u0026gt; [ConfigurationService1, ConfigurationService2,...] --\u0026gt; Cache --\u0026gt; MasterDatabases --\u0026gt; SlaveDatabases At least Cover the following Load balancing and mention a couple of LB algorithms What we\u0026rsquo;re storing in the cache What happens when Load Balancers die and how do you detect it Redundancy: how we can guarantee that we wont lose any configurations What happens when there\u0026rsquo;s a spike of reads because it\u0026rsquo;s Black Friday on Amazon What happens if a Master Database dies What happens if a slave database dies What happens if the cache dies Do we need a CDN? How can we prevent users from storing highly sensitive data in there? Like Credit Card numbers. What happens if a datacenter goes down? Can we recover from that? How? Can we compress the configurations? How much space is that going to save? What\u0026rsquo;s the impact in latency when reading a new configuration? How can we throttle a user that wrote a buggy script and is creating configurations like crazy (and will consume all IDs)? What metrics are you going to monitor? Where do you store the logs? How often do you rotate them? What alarming are you going to put in place? ","permalink":"https://yc0.github.io/posts/design-a-configuration-management-system/","summary":"\u003ch2 id=\"configuration-management-system\"\u003eConfiguration management system\u003c/h2\u003e\n\u003cp\u003eDesign a configuration management system\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUser should be able to add configuration\u003c/li\u003e\n\u003cli\u003eUser should be able to delete configuration\u003c/li\u003e\n\u003cli\u003eUser should be able to search for configuration\u003c/li\u003e\n\u003cli\u003eUser should be able to subscribe to Configuration So that any updates in configuration will gets notfied to user\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"clarify\"\u003eClarify\u003c/h3\u003e\n\u003cp\u003eWe want to design a system to persist configurations that can be used by other systems. Configurations will be managed through an internal portal and will be editable only by the user who created them but can be read by any system through a RESTful API. In addition to CRUD (creation, read, updates and deletions) an user can search for configurations and can subscribe to them to receive notifications every time there\u0026rsquo;s a change.\u003c/p\u003e","title":"Design a configuration management system"},{"content":"Introduction System Design from jiuzhang, talk to you how to prepare your system\nDAU: Daily active user\nInfrastructure\nWeb development\nanalyst duo dilgence\nwork solution special case analysis tradeoff knowledge base 4s\u0026rsquo; analysis\nscenario service storage scale Design systems v.s. Design portion of systems (limit rate of access rate/statistical history)\nBreakdown The Requirements daily active users\nlogin/register user profile\ndisplay/edit storage\ndatabase: sql database =\u0026gt; user table nosql database =\u0026gt; tweets/social graph file system\nmedia files cache\nnonpersistent algorithm/datastructure merge k sorted arrays Design user system - database\u0026amp; memcache design user system - memcached authentication sql vs nosql friendship (MST, kruskal, Prim) how to scale sharding/ consistent hashing/ replica user systems features\nheavy read, light write cache a sort of key-val datastructure, like hashmap in Java memcached =\u0026gt; non-persistence (high performance) redis =\u0026gt; persistence (high cluster) it is not necessary to keep in memory file system could be a cache cpu also has a cache cache.get(\u0026#34;this is a key\u0026#34;, \u0026#34;this is a value\u0026#34;) cache.get(\u0026#34;this is a key\u0026#34;) \u0026gt;\u0026gt; this is a value\ncache.set(\u0026#34;foo\u0026#34;, 1, ttl = 60) // expired within 60 sec cache.get(\u0026#34;foo\u0026#34;) \u0026gt;\u0026gt; 1\n#wait for 60 seconds cache.get(\u0026#34;foo\u0026#34;) \u0026gt;\u0026gt;null\ncache.get(\u0026#34;bar\u0026#34;) \u0026gt;\u0026gt;null\n# memcached optimize the query of DB class UserService: def getUser(self, user_id): key = \u0026#34;user::%s\u0026#34; % user_id How to keep login? session / login After users login, server will create a session instance, and response session_key as a cookie back to a browser.\nThe browser will put the records in the cookie. Customers want to request the service every time. The browser will bring the cookie corresponding to the server, and the server will validate the session_key in cookie. If it is valid, the customer is allowed to access the services.\nsession logout The server will erase/delete a record from a session table. But where is the session table.\nIn general, session table is stored in cache. However, it could be better when stored in database. If customers access frequently, try to adopt cache instead.\nSQL v.s. NOSQL transaction -\u0026gt; cannot use nosql sql -\u0026gt; serialization, secondary index and soon HDrive nosql run 10x+ fast than sql SQL A column is defined by schema with predefinition, and cannot be abitrarily extended. Retrieve record by row NOSQL, opposite to SQL column is dynamic retrieve data by grid ","permalink":"https://yc0.github.io/posts/system-design-overview/","summary":"\u003ch2 id=\"introduction-system-design\"\u003eIntroduction System Design\u003c/h2\u003e\n\u003cp\u003efrom jiuzhang, talk to you how to prepare your system\u003c/p\u003e\n\u003c!-- more --\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eDAU: Daily active user\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInfrastructure\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWeb development\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eanalyst duo dilgence\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ework solution\u003c/li\u003e\n\u003cli\u003especial case\u003c/li\u003e\n\u003cli\u003eanalysis\u003c/li\u003e\n\u003cli\u003etradeoff\u003c/li\u003e\n\u003cli\u003eknowledge base\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e4s\u0026rsquo; analysis\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003escenario\u003c/li\u003e\n\u003cli\u003eservice\u003c/li\u003e\n\u003cli\u003estorage\u003c/li\u003e\n\u003cli\u003escale\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDesign systems v.s. Design portion of systems (limit rate of access rate/statistical history)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"breakdown-the\"\u003eBreakdown The\u003c/h2\u003e\n\u003ch3 id=\"requirements\"\u003eRequirements\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003edaily active users\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003elogin/register\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003euser profile\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003edisplay/edit\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003estorage\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003edatabase: sql database =\u0026gt; user table\u003c/li\u003e\n\u003cli\u003enosql database =\u0026gt; tweets/social graph\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003efile system\u003c/strong\u003e\u003c/p\u003e","title":"System Design Overview"},{"content":"Custom Class with Range-based Loop in C++ Sometimes, you have to invent your own class/structure with iteration demands In modern c++(c++11), it\u0026rsquo;ve alread supplied range-based loop. So what\u0026rsquo;s range-based loop?\nfor(auto it=begin(arr); it!=end(arr); ++it) {} is tradional method to iterate the container. range-based loop looks like for(auto\u0026amp; item : arr). It\u0026rsquo;s more comfortable and readable to do iterate. However, how do we implement the same function on your own class/struct ?\nHow does Range-base loop work In the end, the objects returned do not have to actually be iterators. The for(:) loop, unlike most parts of the C++ standard, is specified to expand to something equivalent to:\nfor( range_declaration : range_expression ) becomes:\n{ auto \u0026amp;\u0026amp; __range = range_expression ; for (auto __begin = begin_expr, __end = end_expr; __begin != __end; ++__begin) { range_declaration = *__begin; loop_statement } } how can/must we do According to previous section, we realize that we have to implement following functions\ninner class iterator operator!= for inner class iterator operator++ for inner class iterator dereference for inner class iterator begin()/end() Here is an example\ntemplate \u0026lt;typename DataType\u0026gt; class PodArray { public: class iterator { public: iterator(DataType * ptr): ptr(ptr){} iterator operator++() { ++ptr; return *this; } bool operator!=(const iterator \u0026amp; other) const { return ptr != other.ptr; } const DataType\u0026amp; operator*() const { return *ptr; } private: DataType* ptr; }; private: unsigned len; DataType *val; public: iterator begin() const { return iterator(val); } iterator end() const { return iterator(val + len); } // rest of the container definition not related to the question ... }; ","permalink":"https://yc0.github.io/posts/custom-class-with-range-based-loop-in-c/","summary":"\u003ch2 id=\"custom-class-with-range-based-loop-in-c\"\u003eCustom Class with Range-based Loop in C++\u003c/h2\u003e\n\u003cp\u003eSometimes, you have to invent your own class/structure with iteration demands\nIn modern c++(c++11), it\u0026rsquo;ve alread supplied range-based loop. So what\u0026rsquo;s range-based loop?\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003efor(auto it=begin(arr); it!=end(arr); ++it) {}\u003c/code\u003e is tradional method to iterate the container. range-based loop looks like \u003ccode\u003efor(auto\u0026amp; item : arr)\u003c/code\u003e. It\u0026rsquo;s more comfortable and readable to do iterate. However, how do we implement the same function on your own class/struct ?\u003c/p\u003e","title":"Custom Class with Range-based Loop in C++"},{"content":"class static member initialization in C++ How we initialize the class static member and make a simliar concept of Java static scope is shown in below 如何初始化Static class member和達成類似Java Static Scope的功能，將是本文紀錄的項目。\nClass Static Member At first, class static member must be initialized, for example.\nclass CFoo { public: CFoo() {} int GetData() { return s_data; } private: static int s_data; }; void main() { CFoo foo; cout \u0026lt;\u0026lt; foo.GetData() \u0026lt;\u0026lt; endl; } it will incur following errors:\nerror LNK2001: unresolved external symbol “private: static int CFoo::s_data” (?s_data@CFoo@@0HA)\nBesides, you CANNOT DO THIS in your class for initialization static member with non-const\nclass CFoo { public: CFoo() : m_b(15) {} private: static int m_a = 15; // not allow static int m_b; }; Complier would tell you:\nerror C2864: ‘CFoo::m_a’ : a static data member with an in-class initializer must have non-volatile const integral type error C2438: ‘m_b’ : cannot initialize static class data via constructor\nWhen mentioning non-const, I also imply that initializing static const variables initialized in class is allowed.\nIn other word, if const static member is integral type in a class, it can be initialized in place.\nclass CFoo { private: static const int m_a = 15; }; Perfectly, for now, we can initial our static members if they are integral and const,non-volatile. But,what if they are not integral type, how can we initialize them ?\nNon-const and Non-integral Type Static Member Inialization If the member is non-itegral and non-const, it is not allowed either.\nclass CFoo { private: static const string m_str = \u0026#34;Bar\u0026#34;; }; Compiler would warn you:\nerror C2864: ‘CFoo::m_str’ : a static data member with an in-class initializer must have non-volatile const integral type\nAs a result, you have to declare static members in a class, and define them outside the class for non-const and non-integral type, for instance :\nclass CFoo { private: static int m_data; static const string m_str; }; int CFoo::m_data = 15; const string CFoo::m_str = \u0026#34;Bar\u0026#34;; Initialize Static Member Using Lambda C++11 also give us great tool-lambda. We can do this like following to fullfill the static block concept like JAVA\nclass A { private: static vector\u0026lt;int\u0026gt; ve; }; vector\u0026lt;int\u0026gt; A::ve = []() -\u0026gt; vector\u0026lt;int\u0026gt; { vector\u0026lt;int\u0026gt; ref(30); return ref; }(); ","permalink":"https://yc0.github.io/posts/static-class-member-initialization-in-c/","summary":"\u003ch2 id=\"class-static-member-initialization-in-c\"\u003eclass static member initialization in C++\u003c/h2\u003e\n\u003cp\u003eHow we initialize the class static member and make a simliar concept of Java static scope is shown in below \u003ccode\u003e如何初始化Static class member和達成類似Java Static Scope的功能，將是本文紀錄的項目\u003c/code\u003e。\u003c/p\u003e\n\u003ch4 id=\"class-static-member\"\u003eClass Static Member\u003c/h4\u003e\n\u003cp\u003eAt first, class static member must be initialized, for example.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eclass CFoo {\npublic:\n    CFoo() {}\n    int GetData() { return s_data; }\nprivate:\n    static int s_data;\n};\n \nvoid main() {\n    CFoo foo;\n    cout \u0026lt;\u0026lt; foo.GetData() \u0026lt;\u0026lt; endl;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eit will incur following errors:\u003c/p\u003e","title":"class static member initialization in C++"},{"content":"C++ vtable/vtable ptr C++中的virtual 本文參考C++中關於 virtual 的兩三事,並且加上自己的經驗而紀錄。\nstatic binding vs. dynamic binding 在 virtual 之前得先提到 binding。binding 一般指的是把一個東西對應到另一個東西上，在 C++ 中，binding 指的是函式呼叫與函式定義的連接，這個時機可能發生於 compile-time 或是 run-time，依據情況而定。 在 static binding 中，compiler 會在 compile-time 時就把函式定義與函式呼叫連結起來，因為比較早連接起來，所以又叫做 early binding。而在 dynamic binding 的情形中，這樣的連接會一直延遲至 run-time 才會發生，因此也可稱為 late binding。在 C++ 中，dynamic binding 主要可以透過 virtual 來達成。 在 static binding 中，由於呼叫函式的所有資訊都已經提前先知道了，所以在程式真正執行起來會比較快一些；反之，dynamic binding 的好處在於在 run-time 才決定，因此可以更彈性地呼叫函式。\nvtable/ vtable ptr 當我們宣告某個 class 的函式為 virtual 時，代表若有 derived class 的話，該函式可以被 redefined。virtual function 的 implementation 是透過 virtual table, or vtable 與 virtual table pointer, or vtable ptr。 只要一個 class 中有一個以上的 virtual 函式，那麼該instance(每一個由該 class 產生的 object)都會包含一個vtable與一個指向這個vtable的指標,vtable ptr。我們可以將 virtual table 想像成陣列，而陣列中的每個元素都是個指向 virtual 函式的 implementation 的指標。\n如底下的程式碼\nclass Base { public: virtual void func1(); virtual void func1(); void nonVirtualFunc(); }; class Derived : public Base { public: virtual void func2() override; void nonVirtualFunc(); }; Derived myDerived; Base myBase; 當我們呼叫一個 instance 的 virtual 函式時，compiler 其實做了這三件事情\n由該 instance的 vtable vptr 找到其 vtable。 找到 vtable 中，符合該函式的指標。 執行前一步指標所指向的位置 在這邊我們有 class Base 含有兩個 virtual 函式 func1(), func2() 與 non-virtual 函式 nonVirtualFunc()，class Derived 繼承 Base，含有 override 的 virtual 函式 func2() 與 non-virtual 函式 nonVirtualFunc()。假設我們有兩個物件：一個 Base 的 object myBase 與另一個 Derived 的 object myDerived。那麼我們可以這樣子想像他們的關係： myBase 物件中包含ptr，該指標指向其 vtable。在這邊因為有兩個 virtual 函式 func1(), func2()，所以 vtable 包含了兩個元素。而這兩個元素分別指向 Base::func1() 的 implementation 與 Base::func2() 的implementation。 myDerived 物件同樣地也包含了指向其 vtable ptr，vtable 也有兩個元素因為有兩個 virtual 函式 func1(), func2()，其中因為 Derived 沒有 override 函式 func1()，所以其指標指向的是 Base::func1() 的 implementation。另一方面，關於函式 func2() 的指標則指向 Derived::func2() 的 implementation\n值得一提的是，vtable 中都不包含關於函式 nonVirtualFunc() 的元素，因為該函式不是 virtual。\nPublic inheritance 裡 class 中的 virtual 函式 接著這邊來討論一下在 inheritance 中，一個 class 裡的函式什麼時候該加 virtual，什麼時候不該加 virtual\n首先我們先定義interface 函式宣告 和 函式定義\ninterface 函式宣告 std::size_t numDigits(int number); implementation 函式定義 std::size_t numDigits(int number) { std::size_t digitsSoFar = 1; while((number/=10)!=0) ++digitsSoFar; return digitsSoFar; } 當我們提到 inheritance 時，我們要先想清楚這個 function 想要繼承的是函式宣告還是函式定義; inheritance of interface 指的是我們只想要繼承函式的宣告，而 inheritance of implementation 則是繼承函式的定義。什麼時候該下 virtual 取決於我們想要繼承的是什麼：有時候只想要繼承函式宣告、有時候想要繼承函式宣告與定義，但允許 override 其定義、有時候想要繼承兩者但不允許 override 其定義。我們可以透過下面這個例子來說明:\nclass Shape { { public: virtual void draw() const = 0; virtual void error(const std::string\u0026amp; msg); int objectID() const; … }; class Rectangle: public Shape{…}; class Ellipse: public Shape{…}; 在這邊 Shape 是個abstract class(不能被具現化instantiated)，因為它包含至少一個純虛擬函式，此外，考慮到 public inheritance 的意義是 is-a(as opposite to private inheritance is has-a)；在任何從 Shape public inherited 的 derived class 中，所有函式的 interface 都必須被繼承。\nPure virtual 純虛擬函式 Pure virtual 的特性使得它們必須被 derived class 重新宣告，且它們在 abstract class 沒有定義。宣告 pure virtual 函式的意義為，derived class 僅僅繼承函式的 interface。\nShape::draw 告訴所有 derived class「你必須提供 draw 函式，至於你要如何 implement 我並不清楚」。在這個例子中也相當正確，畢竟要分別畫出 Rectangle 與 Ellipse 的演算法應該差異非常大\n宣告 pure virtual 函式的意義為，derived class 僅僅繼承函式的 interface\nvirtual 虛擬函式 virtual function or simple virtual function 則稍有不同。首先 derived class 仍然繼承函式的 interface，第二是 simple virtual 函式提供了一個 implementation，即函式定義。但是 derived class 可以 override。意即\n宣告 simple virtual 函式的意義為，derived class 繼承函式的 interface 以及其 default implementation\nShape 透過這個意思告訴所有 derived class「你要提供 error 函式，但如果你不想要寫自己的版本的話，你可以用我的版本」。\nnon-virtual 函式 在 non-virtual 函式中，derived class 最好保留著函式原本的行為，不應該自己重新定義函式。同樣地，加上 derived class 繼承函式的 interface 後，我們可以這樣理解\n宣告 non-virtual 函式的意義為，繼承函式的 interface 以及不更改函式原本的 implementation。\npure virtual/ virtual / non-virtual 小結 綜合上述三者，當一個 class 預計被當成 base class 時，通常都會有為數不少的 virtual 函式。但倘若真的存在某些函式不應該被重新定義時，請不要幫他們任意加上 virtual\nderived chain / inheritance chain 在繼承階層中，第一個建立的建構子是base class，這裡要說明一下，virtual是有穿透性(沒有人這樣形容，但其行為很像，有人再修正我一下, 參考自 When should my destructor be virtual)，Classes按一定的順序執行(Depth-first-left-to-right)，逐步更換vtable 中的implementation。\nThe very first constructors to be executed are the virtual base classes anywhere in the hierarchy. They are executed in the order they appear in a depth-first left-to-right traversal (從base class到derived classes) of the graph of base classes, where left to right refer to the order of appearance of base class names.\nAfter all virtual base class constructors are finished, the construction order is generally from base class to derived class. The details are easiest to understand if you imagine that the very first thing the compiler does in the derived class’s ctor is to make a hidden call to the ctors of its non-virtual base classes (hint: that’s the way many compilers actually do it). So if class D inherits multiply from B1 and B2, the constructor for B1 executes first, then the constructor for B2, then the constructor for D. This rule is applied recursively; for example, if B1 inherits from B1a and B1b, and B2 inherits from B2a and B2b, then the final order is B1a, B1b, B1, B2a, B2b, B2, D.\n小結 virtual是有穿透性:再你的繼承物件中，如果您的基類具有虛擬方法，則您自己的方法是自動虛擬的。由於其他原因，您可能需要明確定義(explicit)方法，但不需要重新聲明virtual，確保它是虛擬的。不管你用虛擬聲明它，沒有虛擬聲明它，或者根本不聲明它，它仍然是虛擬的。 Classes按一定的順序執行(Depth-first-left-to-right)，逐步更換vtable 中的implementation virtual inheritance. 多重繼承時，會有一種模擬兩可的情況，就是當兩個類別都繼承同一個基底類別，而這兩個類別又同時被另一個類別，以平行多重繼承的方式同時繼承 C類別將會擁有兩個A類別的複本，一個來自B1所繼承下來的，一個來自B2所繼承下來的，Compiler將會Confuse C類別的A是來自B1 或B2\nvirtual inheritance可解決這個問題。\nclass A { // implementation }; class B1 : **virtual public A** { // implementation }; class B2 : **virtual public A** { // implementation }; class C : public B1, public B2 { // implementation }; B1與B2以虛擬繼承的方式繼承了A類別，這個好處是當有類別多重繼承了某個基底類別時，在該類別中將會只有一個基底類別存在，而不會有多個複 本\nvirtual destructor 為避免不可預期的錯誤，在security code中，要求base class的destrutor必須virtual。不多說，直接看例子，秒懂。\nDeleting a derived class object using a pointer to a base class that has a non-virtual destructor results in undefined behavior. To correct this situation, the base class should be defined with a virtual destructor. For example, following program results in undefined behavior.\nclass base { public: base() { cout\u0026lt;\u0026lt;\u0026#34;Constructing base \\n\u0026#34;; } ~base() { cout\u0026lt;\u0026lt;\u0026#34;Destructing base \\n\u0026#34;; } }; class derived: public base { public: derived() { cout\u0026lt;\u0026lt;\u0026#34;Constructing derived \\n\u0026#34;; } ~derived() { cout\u0026lt;\u0026lt;\u0026#34;Destructing derived \\n\u0026#34;; } }; output\nConstructing base Constructing derived Destructing base derived的 destructor並未執行，因為這不是override而是hidden。正確的寫法應是：\nclass base { public: base() { cout\u0026lt;\u0026lt;\u0026#34;Constructing base \\n\u0026#34;; } virtual ~base() { cout\u0026lt;\u0026lt;\u0026#34;Destructing base \\n\u0026#34;; } }; class derived: public base { public: derived() { cout\u0026lt;\u0026lt;\u0026#34;Constructing derived \\n\u0026#34;; } ~derived() { cout\u0026lt;\u0026lt;\u0026#34;Destructing derived \\n\u0026#34;; } }; output\nConstructing base Constructing derived Destructing derived Destructing base 結論 virtual 的好處是避免冗余的程式碼，但需要多佔一些空間以及增加run-time，當然還有一些 virtual 的其他小細節\npolymorphic bases class destructor 盡量要 virtual盡量避免讓 virtual 遇上 inline multiple inheritance 中 使用 virtual base class override virtual 函式加上 override確保你正在override一個interface而不是create一個函式。 這裡補完C++中關於 virtual 的兩三事提點的資料。\n","permalink":"https://yc0.github.io/posts/c-vtable-ptr-vtable/","summary":"\u003ch2 id=\"c-vtablevtable-ptr-c中的virtual\"\u003eC++ vtable/vtable ptr C++中的virtual\u003c/h2\u003e\n\u003cp\u003e本文參考\u003ca href=\"https://medium.com/theskyisblue/c-%E4%B8%AD%E9%97%9C%E6%96%BC-virtual-%E7%9A%84%E5%85%A9%E4%B8%89%E4%BA%8B-1b4e2a2dc373\"\u003eC++中關於 virtual 的兩三事\u003c/a\u003e,並且加上自己的經驗而紀錄。\u003c/p\u003e\n\u003c!-- more --\u003e \n\u003ch3 id=\"static-binding-vs-dynamic-binding\"\u003estatic binding vs. dynamic binding\u003c/h3\u003e\n\u003cp\u003e在 virtual 之前得先提到 binding。binding 一般指的是把一個東西對應到另一個東西上，在 C++ 中，binding 指的是函式呼叫與函式定義的連接，這個時機可能發生於 compile-time 或是 run-time，依據情況而定。\n在 static binding 中，compiler 會在 compile-time 時就把函式定義與函式呼叫連結起來，因為比較早連接起來，所以又叫做 early binding。而在 dynamic binding 的情形中，這樣的連接會一直延遲至 run-time 才會發生，因此也可稱為 late binding。在 C++ 中，dynamic binding 主要可以透過 virtual 來達成。\n在 static binding 中，由於呼叫函式的所有資訊都已經提前先知道了，所以在程式真正執行起來會比較快一些；反之，dynamic binding 的好處在於在 run-time 才決定，因此可以更彈性地呼叫函式。\u003c/p\u003e\n\u003ch3 id=\"vtable-vtable-ptr\"\u003evtable/ vtable ptr\u003c/h3\u003e\n\u003cp\u003e當我們宣告某個 class 的函式為 virtual 時，代表若有 derived class 的話，該函式可以被 redefined。virtual function 的 implementation 是透過 virtual table, or vtable 與 virtual table pointer, or vtable ptr。\n只要一個 class 中有一個以上的 virtual 函式，那麼該instance(每一個由該 class 產生的 object)都會包含一個vtable與一個指向這個vtable的指標,vtable ptr。我們可以將 virtual table 想像成陣列，而陣列中的每個元素都是個指向 virtual 函式的 implementation 的指標。\u003c/p\u003e","title":"C++ vtable ptr \u0026 vtable"},{"content":"C++ Print Pretty So for anyone unfamiliar, C++ has a variety of things called manipulators that will change the format of the output printed with \u0026ldquo;cout\u0026rdquo;. These things are not printed themselves, they just affect the part you are actually printing. A list of these manipulators can be found on the reference\nHere is an example\ninput\n100.345 2006.008 2331.41592653498 output\n0x64 _______+2006.01 2.331415927E+03 How can we do that ? Yes, use manipulators\nSource Code double A = 100.345; // 16 bytes for long long double B = 2006.008; double C = 2331.41592653498; // LINE 1 cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; left \u0026lt;\u0026lt; showbase \u0026lt;\u0026lt; nouppercase; // formatting cout \u0026lt;\u0026lt; (long long) A \u0026lt;\u0026lt; endl; // actual printed part // LINE 2 cout \u0026lt;\u0026lt; dec \u0026lt;\u0026lt; right \u0026lt;\u0026lt; setw(15) \u0026lt;\u0026lt; setfill(\u0026#39;_\u0026#39;) \u0026lt;\u0026lt; showpos \u0026lt;\u0026lt; fixed \u0026lt;\u0026lt; setprecision(2); // formatting cout \u0026lt;\u0026lt; B \u0026lt;\u0026lt; endl; // actual printed part // LINE 3 cout \u0026lt;\u0026lt; scientific \u0026lt;\u0026lt; uppercase \u0026lt;\u0026lt; noshowpos \u0026lt;\u0026lt; setprecision(9); // formatting cout \u0026lt;\u0026lt; C \u0026lt;\u0026lt; endl; // actual printed part The explanation shows as follows\nPrint Line 1 hex: output the number in hexadecimal format left: align the number to the left showbase: make sure the hexadecimal number has a \u0026lsquo;0x\u0026rsquo; at the beginning nouppercase: converts all alphabetic hexadecimal values to lowercase. Print Line 2 dec: switches numbers from hexadecimal back to decimal. right: aligns values to the right instead of the left setw(15): sets a fixed width of 15, as the effect from the initial code only impacts the first printed line. setfill(*): by default, when you have a fixed width, if your printed value doesn\u0026rsquo;t fill up the entire length (for example, if you have a width of 15 and only print 7 characters), the extra characters used to pad are whitespaces. This function lets you change the padding to whatever character you want. showpos: Makes sure there is a plus/negative sign before any positive numbers fixed: ensures that number is printed out entirely and that scientific notation isn\u0026rsquo;t used for larger numbers setprecision(*): sets the number of decimal places to 2. Print Line 3 scientific: prints output in scientific notation format uppercase: undoes previous nouppercase manipulator and ensures that the \u0026lsquo;E\u0026rsquo; in the scientific notation is capitalised noshowpos: undoes previous showpos manipulator and gets rid of the plus/negative sign at the start of positive values setprecision: changes the number of digits after the decimal place from 2 to 9. ","permalink":"https://yc0.github.io/posts/c-print-pretty/","summary":"\u003ch2 id=\"c-print-pretty\"\u003eC++ Print Pretty\u003c/h2\u003e\n\u003cp\u003eSo for anyone unfamiliar, C++ has a variety of things called \u003cstrong\u003emanipulators\u003c/strong\u003e that will change the format of the output printed with \u0026ldquo;cout\u0026rdquo;. These things are not printed themselves, they just affect the part you are actually printing. A list of these manipulators can be found on \u003ca href=\"http://www.cplusplus.com/reference/library/manipulators/\"\u003ethe reference\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eHere is an example\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003einput\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e100.345 2006.008 2331.41592653498\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eoutput\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e0x64             \n_______+2006.01  \n2.331415927E+03\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eHow can we do that ? Yes, use \u003cstrong\u003emanipulators\u003c/strong\u003e\u003c/p\u003e","title":"C++ Print Pretty"},{"content":"AWS儲存型式 Recently, we dicussed that how to supply storages for persistent volumes of Kuberenetes. There\u0026rsquo;re plenty of types shown on official website. Many peopel including my folks don\u0026rsquo;t realize what are the difference and what are they suitable for ? As a solution architect, there\u0026rsquo;re no absoluate answer for an answer. It depends on what kind of applications you face. Today, I want to mention two types : block-based(BLK) and file-based storage(NFS) , and counterparts in AWS. The materials come from Business Professional Accrediated\nAWS EBS useful fro file-based workloads enterprise application relational database NOSQL database application where consistency \u0026amp; low-latency performance is required In sum, low-latency and log-file- based databases whatever for transaction solutions, such as WSREP, WAL or partitioned files in Kafka, are all suitable for EBS.\nAWS EFS A managed-services of NFS in AWS.\nfile storage server create and configure file systems capacity is elastic grow and shrink automatically as files are added or removed In sum, just like traditional file storage server with elasticity, but you might occur a little bit latency due to propagation for consistency.\n","permalink":"https://yc0.github.io/posts/aws-storage-type/","summary":"\u003ch2 id=\"aws儲存型式\"\u003eAWS儲存型式\u003c/h2\u003e\n\u003cp\u003eRecently, we dicussed that how to supply storages for persistent volumes of Kuberenetes. There\u0026rsquo;re plenty of types shown on official website. Many peopel including my folks don\u0026rsquo;t realize what are the difference and what are they suitable for ? As a solution architect, there\u0026rsquo;re no absoluate answer for an answer. It depends on what kind of applications you face. Today, I want to mention two types : block-based(BLK) and file-based storage(NFS) , and counterparts in AWS. The materials come from Business Professional Accrediated\u003c/p\u003e","title":"AWS Storage Type"}]